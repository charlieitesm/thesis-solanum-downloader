{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uN6zYEawlMlr"
   },
   "source": [
    "# Solanum identifier using Neural Networks\n",
    "\n",
    "Contains the code to balance classes and create the training/val/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPH7eaLgldoa"
   },
   "source": [
    "# Environment preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5uPdt9-ljNr"
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0bSI4aoqjg5"
   },
   "outputs": [],
   "source": [
    "!pip install -U keras tensorflow matplotlib numpy pandas imblearn split-folders tensorflow-addons\n",
    "!pip install -q \"tqdm>=4.36.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0_bFpHvq7lu"
   },
   "source": [
    "## Env vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPhSt_peq9Ts",
    "outputId": "9e198481-0781-4a8c-9358-18fe05730966"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATA_LOCATION=P:\\CODE\\ITESM\\tesis-dataset-downloader\\solanum_output\n",
      "env: CLEAN_DATA_FOLDER=z_clean_resized\n",
      "env: CLEAN_SPLIT_DATA_FOLDER=z_clean_resized_split\n",
      "P:\\CODE\\ITESM\\tesis-dataset-downloader\\solanum_output\n"
     ]
    }
   ],
   "source": [
    "# Set this variable to the root path of where the files are located\n",
    "%env DATA_LOCATION=P:\\CODE\\ITESM\\tesis-dataset-downloader\\solanum_output\n",
    "%env CLEAN_DATA_FOLDER=z_clean_resized\n",
    "%env CLEAN_SPLIT_DATA_FOLDER=z_clean_resized_split\n",
    "\n",
    "#%env DATA_LOCATION=/workspace/jupyter_workspace/tesis\n",
    "#%env DATA_LOCATION=/content/drive/MyDrive/Datasets/AndroidOrIos\n",
    "!echo %DATA_LOCATION%\n",
    "\n",
    "#!dir %DATA_LOCATION%\n",
    "\n",
    "# Constants\n",
    "import os\n",
    "\n",
    "RANDOM_SEED = 1988\n",
    "DATA_ROOT_LOCATION = os.environ[\"DATA_LOCATION\"]\n",
    "CLEAN_DATA_FOLDER = os.environ[\"CLEAN_DATA_FOLDER\"]\n",
    "CLEAN_SPLIT_DATA_FOLDER = os.environ[\"CLEAN_SPLIT_DATA_FOLDER\"]\n",
    "\n",
    "LABELS = [\n",
    "            \"petota\",\n",
    "            \"holophylla\",\n",
    "            \"melongena\",\n",
    "            \"torva\",\n",
    "            \"brevantherum\",\n",
    "            \"solanum\",\n",
    "            \"dulcamara\",\n",
    "            \"herposolanum\",\n",
    "            \"micracantha\",\n",
    "            \"lasiocarpa\",\n",
    "            \"acanthophora\",\n",
    "            \"anarrhichomenum\",\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hjRe6pZqsjq"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2pgESWUIqu-2",
    "outputId": "ef1c54d6-4444-42e9-95d7-3645161cbb2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# tqdm Progress Bar\n",
    "import tqdm\n",
    "\n",
    "# quietly deep-reload tqdm\n",
    "#import sys\n",
    "#from IPython.lib import deepreload \n",
    "\n",
    "#stdout = sys.stdout\n",
    "#sys.stdout = open('junk','w')\n",
    "#deepreload.reload(tqdm)\n",
    "#sys.stdout = stdout\n",
    "# As shown in https://www.tensorflow.org/addons/tutorials/tqdm_progress_bar\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import splitfolders\n",
    "\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "#import sklearn.model_selection as model_selection\n",
    "\n",
    "#from imutils import paths\n",
    "#import shutil\n",
    "\n",
    "import os\n",
    "import time\n",
    "#import random\n",
    "\n",
    "# Enable 3rd Party Jupyter Widgets in Google Collab\n",
    "#from google.colab import output\n",
    "#output.enable_custom_widget_manager()\n",
    "\n",
    "def get_training_device_name():\n",
    "    name = tf.test.gpu_device_name()\n",
    "\n",
    "    if \"GPU\" not in name:\n",
    "        print(\"No GPU was found!, training will be done in the CPU which will be slower\")\n",
    "        name = '/cpu:0'\n",
    "    else:\n",
    "        print('Found GPU at: {}'.format(name))\n",
    "    \n",
    "    return name\n",
    "\n",
    "TRAINING_DEVICE_NAME = get_training_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSOAYz0vllMB"
   },
   "source": [
    "## Files description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "9SnVocu9reZR",
    "outputId": "6844e262-cbad-4641-b31c-28db22c24fbd"
   },
   "outputs": [],
   "source": [
    "images_df = pd.read_csv(os.path.join(DATA_ROOT_LOCATION, CLEAN_DATA_FOLDER, \"images_dedup_512x512_100picspersection.csv\"))\n",
    "\n",
    "# Update all paths to conform to the local structure (Only if running in a UN*X environment)\n",
    "\n",
    "# 'P:/CODE/ITESM/tesis-dataset-downloader/solanum_output/z_clean_resized/acanthophora/acanthophora_acerifolium_1928496814_gbif_2700.jpg'\n",
    "# path_to_replace = \"P:/CODE/ITESM/tesis-dataset-downloader/solanum_output/z_clean_resized\"\n",
    "# images_df[\"full_path\"] = images_df[\"full_path\"].str.replace(path_to_replace, data_root_location)\n",
    "\n",
    "display(images_df.describe(include=\"all\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibv28UY_lqca"
   },
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mrm8zHONSweF"
   },
   "outputs": [],
   "source": [
    "def print_marquee(msg: str):\n",
    "    \"\"\"\n",
    "    Prints a centered message with a marquee of * \n",
    "    \"\"\"\n",
    "    marquee_width = len(msg) + 4\n",
    "    print(\"\\n\")\n",
    "    print(\"*\" * marquee_width)\n",
    "    print(f\"* {msg} *\")\n",
    "    print(\"*\" * marquee_width)\n",
    "\n",
    "def model_2_pkl(model, filename: str):\n",
    "    \"\"\"Exports a model to PKL format\"\"\"\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "def pkl_2_model(filename: str):\n",
    "    \"\"\"Loads a model from a PKL file\"\"\"\n",
    "    return pickle.load(open(filename, 'rb'))\n",
    "\n",
    "def train_model(model_to_fit: tf.keras.models.Model,\n",
    "                fit_params: dict):\n",
    "\n",
    "    t = time.process_time()\n",
    "    \n",
    "    trained_model = model_to_fit.fit(**fit_params)\n",
    "    \n",
    "    elapsed_time = time.process_time() - t\n",
    "    \n",
    "    print(f\"\\n\\n ********* Training time: {elapsed_time} s.\")\n",
    "    return trained_model\n",
    "\n",
    "def graph_loss_accuracy(h_model,\n",
    "                        subtitle: str = \"\"):\n",
    "    \n",
    "    num_records = len(h_model.history[\"accuracy\"])\n",
    "    \n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0,num_records),h_model.history[\"accuracy\"],label=\"train_acc\")\n",
    "    plt.plot(np.arange(0,num_records),h_model.history[\"val_accuracy\"],label=\"val_acc\")\n",
    "    plt.title(\"Training and Validation Accuracy\" \n",
    "              + f\" ({subtitle})\" if subtitle else \"\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0,num_records),h_model.history[\"loss\"],label=\"train_loss\") \n",
    "    plt.plot(np.arange(0,num_records),h_model.history[\"val_loss\"],label=\"val_loss\")\n",
    "    plt.title(\"Training and Validation Loss\" \n",
    "              + f\" ({subtitle})\" if subtitle else \"\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Helper functions for reporting\n",
    "\n",
    "def print_dataset_prediction_report(y_pred,\n",
    "                                    y_real,\n",
    "                                    labels: list=None):\n",
    "    \n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "    print_marquee(\"Classification Report\")\n",
    "    print(classification_report(y_real,\n",
    "                                y_pred,\n",
    "                                target_names=labels))\n",
    "    \n",
    "    print_marquee(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(y_real,\n",
    "                           y_pred))\n",
    "\n",
    "\n",
    "def evaluate_model(model_to_fit: tf.keras.models.Model,\n",
    "                   fit_params: dict,\n",
    "                   labels: list = None) -> tf.keras.models.Model:\n",
    "\n",
    "    trained_model_history = train_model(\n",
    "                                        model_to_fit,\n",
    "                                        fit_params,\n",
    "                                       )\n",
    "    print_marquee(\"Model Summary\")                                \n",
    "    model_to_fit.summary()\n",
    "\n",
    "    print_marquee(\"Validation Dataset Confusion Matrix\")\n",
    "\n",
    "    val_model_predictions = model_to_fit.predict(fit_params[\"validation_data\"],\n",
    "                                                 fit_params[\"batch_size\"])\n",
    "    \n",
    "    print_dataset_prediction_report(val_model_predictions,\n",
    "                                    fit_params[\"validation_data\"][1],\n",
    "                                    labels)\n",
    "\n",
    "    print_marquee(\"Train/Val Accuracy and Loss graphs\")\n",
    "\n",
    "    # If using early stopping, it might be the case that we used less epochs than\n",
    "    #  requested\n",
    "    subtitle = f\"Epochs: {len(trained_model_history.history['accuracy'])}\"\n",
    "    \n",
    "    graph_loss_accuracy(trained_model_history,\n",
    "                        subtitle=subtitle)\n",
    "    \n",
    "    return model_to_fit, trained_model_history\n",
    "\n",
    "def create_model_checkpoint(filepath: str) -> tf.keras.callbacks.ModelCheckpoint:\n",
    "    return tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath,\n",
    "            monitor = 'val_loss',\n",
    "            verbose = 0,\n",
    "            save_best_only = True,\n",
    "            save_weights_only = False,\n",
    "            mode = 'auto',\n",
    "            save_freq='epoch',\n",
    "            options=None,\n",
    "            initial_value_threshold=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxbH2G3Dl1aa"
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnXDd2tEmaXC"
   },
   "source": [
    "## Data at a glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8IF608kjTUmx",
    "outputId": "9884e707-0a42-4352-c234-f18f42852518"
   },
   "outputs": [],
   "source": [
    "print_marquee(\"Classes\")\n",
    "count_per_section = images_df.groupby([\"section\"]).size().reset_index(name='count').sort_values(\"count\", ascending=False)\n",
    "display(count_per_section)\n",
    "\n",
    "display(count_per_section.describe())\n",
    "\n",
    "print_marquee(\"Info\")\n",
    "display(images_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H39MiKoUmeKC"
   },
   "source": [
    "## Balancing of classes TBD\n",
    "\n",
    "We can see that there are classes that are overrepresented, so we need to do some undersampling and oversampling in order for the model to better learn and classify.\n",
    "\n",
    "The average count for the samples is `709.58` while the median is `483` (listed as the 2nd quartile or 50%), so the best strategy that will be employed is to randomly undersample anything above `500` and oversample anything below that level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "1DG9JtG2UG5L",
    "outputId": "10495cbe-3041-4ed8-ff15-234c4c89ec43"
   },
   "outputs": [],
   "source": [
    "# https://imbalanced-learn.org/stable/\n",
    "undersampler = RandomUnderSampler(sampling_strategy='all',\n",
    "                                  random_state=RANDOM_SEED)\n",
    "\n",
    "oversampler = RandomOverSampler(sampling_strategy='auto',\n",
    "                                  random_state=RANDOM_SEED)\n",
    "\n",
    "X_train_res, y_train_res = oversampler.fit_resample(X_train,\n",
    "                                                    y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnTMtJdCErq9"
   },
   "source": [
    "## Train/Val/Test split\n",
    "\n",
    "For this part we'll use 70/20/10 split for the train, validation and tests datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eO5rqruNErVi",
    "outputId": "2ecbcea2-e931-4525-a7d5-253a76602511"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#splitfolders.ratio(os.path.join(DATA_ROOT_LOCATION, CLEAN_DATA_FOLDER), # The location of dataset\n",
    "#                   output=os.path.join(DATA_ROOT_LOCATION, CLEAN_SPLIT_DATA_FOLDER), # The output location\n",
    "#                   seed=RANDOM_SEED, # The number of seed\n",
    "#                   ratio=(.7, .2, .1), # The ratio of splited dataset\n",
    "#                   group_prefix=None, # If your dataset contains more than one file like \".jpg\", \".pdf\", etc\n",
    "#                   move=False # If you choose to move, turn this into True\n",
    "#                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnNpYgx_miPc"
   },
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHUxdqdlXsq2",
    "outputId": "42cfaf44-59af-44d4-b299-cf443b6337f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5955 images belonging to 12 classes.\n",
      "Found 1698 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "TARGET_SIZE = (64, 64)\n",
    "BATCH_SIZE = 8\n",
    "COLOR_MODE = \"rgb\"\n",
    "\n",
    "def get_image_data_gen_params():\n",
    "    return {\n",
    "        \"target_size\": TARGET_SIZE,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"color_mode\": COLOR_MODE,\n",
    "        \"class_mode\": \"categorical\",\n",
    "        \"seed\": RANDOM_SEED,\n",
    "        \"save_prefix\": 'augmented_',\n",
    "        \"save_format\": 'png'\n",
    "    }\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "            rescale=1.0/255, # Normalize the data to be 0-1\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(DATA_ROOT_LOCATION, CLEAN_SPLIT_DATA_FOLDER, \"train\"),\n",
    "        save_to_dir=os.path.join(DATA_ROOT_LOCATION, CLEAN_SPLIT_DATA_FOLDER, \"train\"),\n",
    "        **get_image_data_gen_params())\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        os.path.join(DATA_ROOT_LOCATION, CLEAN_SPLIT_DATA_FOLDER, \"val\"),\n",
    "        save_to_dir=os.path.join(DATA_ROOT_LOCATION, CLEAN_SPLIT_DATA_FOLDER, \"val\"),\n",
    "        **get_image_data_gen_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCRm879znyPf"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKVXFZJunz_e"
   },
   "source": [
    "## Manual VGG8 TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zY7mmFsWmh5r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZQ9lLZHn6Ep"
   },
   "source": [
    "## Manual VGG16 TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwK-uZXBlhk6"
   },
   "outputs": [],
   "source": [
    "|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrcmEFB_oAlS"
   },
   "source": [
    "## VGG8 TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlSU784noB8n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAO099QKoDvx"
   },
   "source": [
    "## VGG16 TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "id": "3tATT1GPoGNP",
    "outputId": "7fe2e40b-0beb-4e97-85d9-b115e8be30b9"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vgg16_tf_model = tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    classes=12,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "# Add an optimizer\n",
    "vgg16_tf_model.compile(optimizer=\"adam\",\n",
    "                        loss='categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "# Add a progress bar and save checkpoints\n",
    "vgg16_callbacks = [\n",
    "    create_model_checkpoint(os.path.join(DATA_ROOT_LOCATION, \"vgg16\")),\n",
    "    tfa.callbacks.TQDMProgressBar()\n",
    "    #tf.keras.callbacks.ProgbarLogger(\n",
    "    #    count_mode = 'steps',\n",
    "    #    stateful_metrics = None\n",
    "    #)\n",
    "]\n",
    "\n",
    "\n",
    "with tf.device(TRAINING_DEVICE_NAME):\n",
    "    evaluate_model(vgg16_tf_model,\n",
    "                   fit_params = {\n",
    "                            \"x\": train_generator,\n",
    "                            \"batch_size\": BATCH_SIZE,\n",
    "                            \"epochs\": 10,\n",
    "                            \"callbacks\": vgg16_callbacks,\n",
    "                            \"validation_data\": validation_generator,\n",
    "                            \"steps_per_epoch\": 64,\n",
    "                            \"validation_freq\": 1,\n",
    "                            \"max_queue_size\": 1,\n",
    "                            \"workers\": 1,\n",
    "                            \"use_multiprocessing\": False\n",
    "                   },\n",
    "                   labels = LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7gJUIGppATL"
   },
   "source": [
    "## ResNET50 TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fAp65U5EpDLf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25088/256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wH1xAp1QpEGM"
   },
   "source": [
    "## State of the art TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvhzU2gnpFrd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "dnXDd2tEmaXC",
    "H39MiKoUmeKC",
    "hnTMtJdCErq9"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
